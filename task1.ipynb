{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (156060, 4)\n",
      "Number of unique sentences: 8529\n"
     ]
    }
   ],
   "source": [
    "print 'Train shape: {}'.format(df_train.shape)\n",
    "print 'Number of unique sentences: {}'.format(len(df_train.loc[:, 'SentenceId'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Distribution of sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_sentiment = df_train.loc[:,'Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb8AAAE/CAYAAADWo82qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTFgWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f140191f9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.title('The distribution of all labels')\n",
    "bins = [-0.4, 0.4,0.6, 1.4, 1.6, 2.4, 2.6, 3.4, 3.6,4.4 ]\n",
    "counts, bins, patches = plt.hist(col_sentiment, bins=bins, align='mid')\n",
    "\n",
    "for i in xrange(5):\n",
    "    s = str(int(counts[2*i])) + '/{:.2f}%'.format(counts[2*i]/sum(counts)*100)\n",
    "    ax.text(i-0.4, counts[2*i]+400, s)\n",
    "\n",
    "xlabels = ['Negative', 'Somewhat negative', 'Neutral', 'Somewhat positive', 'Positive']\n",
    "_ = ax.set_xticklabels([''] + xlabels)\n",
    "\n",
    "del col_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is imbalanced, half of its labels are Neutral "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.2 Distribution of sentence sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF shape:(8529, 4)\n"
     ]
    }
   ],
   "source": [
    "df_sentences = df_train.drop_duplicates(subset='SentenceId', keep='first')\n",
    "print 'DF shape:{}'.format(df_sentences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  SentenceId                                             Phrase  \\\n",
       "0          1           1  A series of escapades demonstrating the adage ...   \n",
       "63        64           2  This quiet , introspective and entertaining in...   \n",
       "\n",
       "    Sentiment  \n",
       "0           1  \n",
       "63          4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentences.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbkAAAE/CAYAAADbvb3tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTok+ccEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f140324b0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "col_sentence_sentiment = df_sentences.loc[:,'Sentiment']\n",
    "\n",
    "fig = plt.figure(figsize=(7,5))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.title('The distribution of sentence sentiments')\n",
    "bins = [-0.4, 0.4,0.6, 1.4, 1.6, 2.4, 2.6, 3.4, 3.6,4.4 ]\n",
    "counts, bins, patches = plt.hist(col_sentence_sentiment, bins=bins, align='mid')\n",
    "\n",
    "for i in xrange(5):\n",
    "    s = str(int(counts[2*i])) + '/{:.2f}%'.format(counts[2*i]/sum(counts)*100)\n",
    "    ax.text(i-0.4, counts[2*i]+20, s)\n",
    "\n",
    "xlabels = ['Negative', 'Somewhat negative', 'Neutral', 'Somewhat positive', 'Positive']\n",
    "_ = ax.set_xticklabels([''] + xlabels)\n",
    "\n",
    "del col_sentence_sentiment, df_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above figures reveal differences between sentence sentiments and dataset sentiments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本处理类\n",
    "(1)所有word均小写化处理  \n",
    "(2)使用空格代替除了[a-zA-Z.!?]的所有字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import re\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "class WordDictionary:\n",
    "    \"\"\"\n",
    "    case insensitive \n",
    "    \"\"\"\n",
    "    def __init__(self, n_grams=1, lemmatization=False):\n",
    "        self.word2index = {'<unknown>':0}\n",
    "        self.index2word = {0:'<unknown>'}\n",
    "        self.n_words = 1\n",
    "        self.wordCounts = {}\n",
    "        self.n_grams = n_grams\n",
    "        self.lemmatization = lemmatization\n",
    "    def addSentence(self, sentence):\n",
    "        s = sentence.lower()\n",
    "        s = re.sub(r'[^a-zA-Z.!?]',r' ', s)\n",
    "        words = s.split()\n",
    "\n",
    "        for idx in xrange(len(words)):\n",
    "            for i in xrange(self.n_grams):\n",
    "                if idx+i<len(words):\n",
    "                    original_word = \" \".join(words[idx:idx+i+1])\n",
    "                    self.addWord(original_word)\n",
    "                    if self.lemmatization:\n",
    "                        lemmatized_word = self.lemmatizeWord(original_word)\n",
    "                        if lemmatized_word!=original_word:\n",
    "                            self.addWord(lemmatized_word)\n",
    "                else:\n",
    "                    break\n",
    "    def addWord(self, word):\n",
    "        if not self.word2index.has_key(word):\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "            self.wordCounts[word] = 1\n",
    "        else:\n",
    "            self.wordCounts[word] += 1\n",
    "    def lemmatizeWord(self, word):\n",
    "        \"\"\"\n",
    "        word: can be blank separated word\n",
    "        \"\"\"\n",
    "        word_ = word.split()\n",
    "        lemmatized_words = []\n",
    "        for w in word_:\n",
    "            lemmatized_words.append(wnl.lemmatize(w))\n",
    "        return \" \".join(lemmatized_words)\n",
    "    \n",
    "    def filterWords(self, min_val = None, max_val=None, verbose=True):\n",
    "        \"\"\"\n",
    "        min_val: int. Occurrence counts lower than this value will be returned.\n",
    "        max_val: int. Occurrence counts bigger than this value will be returned. \n",
    "        \"\"\"\n",
    "        words = []\n",
    "        print_words = []\n",
    "        for k, v in self.wordCounts.iteritems():\n",
    "            if min_val!=None and v <= min_val:\n",
    "                words.append(k)\n",
    "                print_words.append((k,v))\n",
    "            if max_val!=None and v >= max_val:\n",
    "                words.append(k)\n",
    "                print_words.append((k,v))\n",
    "        if verbose:\n",
    "            print print_words\n",
    "        return words\n",
    "    def dropAndReindex(self, dropWords):\n",
    "        \"\"\"\n",
    "        dropWords: delete word in dropWords\n",
    "        \"\"\"\n",
    "        need_reindex = False\n",
    "        for word in dropWords:\n",
    "            if self.word2index.has_key(word):\n",
    "                self.word2index.pop(word)\n",
    "                self.wordCounts.pop(word)\n",
    "                need_reindex = True\n",
    "        if need_reindex:\n",
    "            self.n_words = 1\n",
    "            tmp_dict = deepcopy(self.word2index)\n",
    "            self.word2index = {'<unknown>':0}\n",
    "            self.index2word = {0:'<unknown>'}  \n",
    "            for k,v in tmp_dict.iteritems():\n",
    "                self.word2index[k] = self.n_words\n",
    "                self.index2word[self.n_words] = word\n",
    "                self.n_words += 1\n",
    "            print \"Finish reindex\"\n",
    "        else:\n",
    "            print 'No need to reindex'\n",
    "    \n",
    "    def convertToVector(self, sentence, count=True, sparse=False):\n",
    "        \"\"\"\n",
    "        sentence: str, blank seperated sentence\n",
    "        count:boolean. If yes, the vector's entry means the number of occurrence\n",
    "        sparse: boolean. If yes, the vector will be sparse\n",
    "        \"\"\"\n",
    "        words = sentence.lower().split()\n",
    "        data = []\n",
    "        for idx in xrange(len(words)):\n",
    "            for i in xrange(self.n_grams):\n",
    "                if idx+i<len(words):\n",
    "                    original_word = \" \".join(words[idx:idx+i+1])\n",
    "                    if self.word2index.has_key(original_word):\n",
    "                        data.append(self.word2index[original_word])\n",
    "                    else:\n",
    "                        data.append(self.word2index['<unknown>'])                    \n",
    "                    if self.lemmatization:\n",
    "                        lemmatized_word = self.lemmatizeWord(original_word)\n",
    "                        if lemmatized_word!=original_word:\n",
    "                            if self.word2index.has_key(lemmatized_word):\n",
    "                                data.append(self.word2index[lemmatized_word])                         \n",
    "                else:\n",
    "                    break\n",
    "        if not count:\n",
    "            data = np.unique(data)\n",
    "        if sparse:\n",
    "            length = len(data)\n",
    "            res = csc_matrix((np.ones(length), (np.zeros(length), data)), shape=(1, self.n_words))\n",
    "        else:\n",
    "            res = np.zeros((1, self.n_words))\n",
    "            for d in data:\n",
    "                res[0, d] += 1\n",
    "        return res\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集拆分以及word向量化方法\n",
    "由于数据中大量存在0，所以这里使用了sparse的表示方法来表示词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import scipy\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "def val_split(df, val_size=0.2):\n",
    "    \"\"\"\n",
    "    This method considers Stratified sampling.\n",
    "    \"\"\"\n",
    "    y = df.iloc[:, -1]\n",
    "    classes = y.unique()\n",
    "    train_idx = []\n",
    "    val_idx = []\n",
    "    for class_ in classes:\n",
    "        bool_indexes = (y==class_)\n",
    "        indexes = y[bool_indexes].index.tolist()\n",
    "        length = len(indexes)\n",
    "        random.shuffle(indexes)\n",
    "        train_idx.extend(indexes[:-int(length*val_size)])\n",
    "        val_idx.extend(indexes[-int(length*val_size):])\n",
    "    random.shuffle(train_idx)\n",
    "    random.shuffle(val_idx)\n",
    "        \n",
    "    return train_idx, val_idx\n",
    "\n",
    "def word2index(df_data, words, count=True, sparse=True):\n",
    "    Xs = []\n",
    "    ys = []\n",
    "    for data in df_data.itertuples():\n",
    "        Xs.append(words.convertToVector(data[1],count=count, sparse=sparse))\n",
    "        ys.append(data[2])\n",
    "    if isinstance(Xs[0], scipy.sparse.csc.csc_matrix):\n",
    "        Xs = vstack(Xs,format='csc')\n",
    "    else:\n",
    "        Xs = np.array(Xs)\n",
    "    return Xs, np.asarray(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression模型相关的内容\n",
    "由于数据不平衡，这里自动将各label的比例作为class_weight参与训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AccuracyLossAndGradient(target, predicts, class_weight):\n",
    "    xindex = np.arange(predicts.shape[0], dtype=int)\n",
    "    yindex = np.zeros(predicts.shape[0],dtype=int)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return loss, grads    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CrossEntropyLossAndGradient(target, predicts, class_weights):\n",
    "    xindex = np.arange(predicts.shape[0], dtype=int)\n",
    "    yindex = np.zeros(predicts.shape[0],dtype=int)\n",
    "    predict_idx = np.argmax(predicts, axis=1)\n",
    "    \n",
    "    class_weights = np.repeat(class_weights.reshape((1, predicts.shape[1])), predicts.shape[0], axis=0)\n",
    "    class_weights = class_weights[xindex, 0]\n",
    "    \n",
    "    loss = -np.log(predicts[xindex, target])*class_weights\n",
    "    \n",
    "    grads = np.repeat(predicts[:,:1], predicts.shape[1], axis=1)\n",
    "    grads[xindex, target] -= predicts[xindex, yindex]/predicts[xindex, target]\n",
    "    loss = np.mean(loss)\n",
    "    grads *= class_weights.reshape((-1, 1))\n",
    "    return loss, grads\n",
    "\n",
    "def get_batch_index(total_samples, batch_size):\n",
    "    sindex = 0\n",
    "    eindex = batch_size\n",
    "    while eindex<total_samples:\n",
    "        yield sindex, eindex\n",
    "        sindex = eindex\n",
    "        eindex += sindex\n",
    "    if sindex<total_samples:\n",
    "        yield sindex, total_samples\n",
    "        \n",
    "def SGD(f, w0, b0, Xs, ys, step=0.1, eps=0.00001, iterations=20, \n",
    "                    print_every=10, batch_size=512, shuffle=False):\n",
    "    iter = 0\n",
    "    while iter<iterations:\n",
    "        if shuffle:\n",
    "            indexes = np.arange(X.shape[0])\n",
    "            random.shuffle(indexes)\n",
    "            Xs = Xs[indexes]\n",
    "            ys = ys[indexes]\n",
    "        for sindex, eindex in get_batch_index(Xs.shape[0], batch_size):\n",
    "            x = Xs[sindex:eindex]\n",
    "            y = ys[sindex:eindex]\n",
    "            loss, gradW, gradB = f(w0, b0, Xs, ys)\n",
    "            delta_w = step*gradW\n",
    "            delta_b = step*gradB\n",
    "            w0 = w0 - delta_w\n",
    "            b0 = b0 - delta_b\n",
    "        \n",
    "        iter += 1\n",
    "        if iter%print_every==0:\n",
    "            print \"[{}/{}] loss:{:.4f}\".format(iter, iterations, loss)\n",
    "        if np.sqrt(np.sum(delta_w*delta_w))<eps or loss<0.001:\n",
    "            print \"Small gradient or loss detects, finish looping...\"\n",
    "            break\n",
    "    return w0, b0    \n",
    "\n",
    "def GradientDescent(f, w0, b0, Xs, ys, step=1, eps=0.00001, iterations=200, \n",
    "                    print_every=10, batch_size=512, shuffle=False):\n",
    "    \"\"\"\n",
    "    f(w0, b0, X, y): return loss, gradw, gradb\n",
    "    \"\"\"\n",
    "    iter = 0\n",
    "    while iter<iterations:\n",
    "        losses = gradWs = gradBs = 0\n",
    "        counter = 0\n",
    "        if shuffle:\n",
    "            indexes = np.arange(X.shape[0])\n",
    "            random.shuffle(indexes)\n",
    "            Xs = Xs[indexes]\n",
    "            ys = ys[indexes]\n",
    "        for sindex, eindex in get_batch_index(Xs.shape[0], batch_size):\n",
    "            x = Xs[sindex:eindex]\n",
    "            y = ys[sindex:eindex]\n",
    "            loss, gradW, gradB = f(w0, b0, Xs, ys)\n",
    "            losses += loss\n",
    "            gradWs += gradW\n",
    "            gradBs += gradB\n",
    "            counter += 1\n",
    "        \n",
    "        losses /= counter\n",
    "        gradWs /= counter\n",
    "        gradBs /= counter\n",
    "        \n",
    "        delta_w = step*gradWs\n",
    "        delta_b = step*gradBs\n",
    "        w0 = w0 - delta_w\n",
    "        b0 = b0 - delta_b\n",
    "        \n",
    "        iter += 1\n",
    "        if iter%print_every==0:\n",
    "            print \"[{}/{}] loss:{:.4f}\".format(iter, iterations, losses)\n",
    "        if np.sqrt(np.sum(delta_w*delta_w))<eps or loss<0.001:\n",
    "            print \"Small gradient or loss detects, finish looping...\"\n",
    "            break\n",
    "    return w0, b0\n",
    "    \n",
    "class LogisticRegression:\n",
    "    def __init__(self, C=0.1, step=0.1):\n",
    "        self.C = C\n",
    "        self.step = step\n",
    "    def fit(self, Xs, ys, val_Xs=None, val_ys=None, class_weights='balanced', loss_f=CrossEntropyLossAndGradient, \n",
    "            update=SGD, batch_size=4096, max_iter=200):\n",
    "        n_classes = len(np.unique(ys))\n",
    "        self.weights = np.zeros((Xs.shape[1], n_classes-1))\n",
    "        self.bias = np.zeros((1, n_classes-1))\n",
    "        \n",
    "        if class_weights=='balanced':\n",
    "            class_weights = np.bincount(ys)\n",
    "            class_weights = float(max(class_weights))/class_weights\n",
    "        else:\n",
    "            class_weights = np.ones(n_classes)\n",
    "        \n",
    "        def f(w0, b0, x, y):\n",
    "            if isinstance(x, scipy.sparse.csc.csc_matrix):\n",
    "                mul = np.dot(x, csc_matrix(w0)).toarray()\n",
    "            else:\n",
    "                mul = np.dot(x, w0)\n",
    "            predicts = np.exp(mul + b0)\n",
    "            norm = 1 + np.sum(predicts, axis=1, keepdims=True)\n",
    "            predicts = np.concatenate((np.ones((predicts.shape[0], 1)), predicts), axis=1)\n",
    "            norm_predicts = predicts/norm\n",
    "            loss, grads = loss_f(y, norm_predicts, class_weights)\n",
    "            \n",
    "            grads = predicts * grads\n",
    "            gradW = np.dot(x.T, csc_matrix(grads[:, 1:])).toarray()\n",
    "            gradW /= x.shape[0]\n",
    "            gradB = np.mean(grads[:, 1:], axis=0)\n",
    "            \n",
    "            w_regularize = 0.5*np.sum(np.sqrt(np.sum(w0*w0, axis=0)))\n",
    "            loss += self.C*w_regularize\n",
    "            gradW += self.C*w0\n",
    "            \n",
    "            return loss, gradW, gradB\n",
    "        \n",
    "        self.weights, self.bias = update(f, self.weights, self.bias, Xs, ys, step=self.step, \n",
    "                                                  batch_size=batch_size, iterations=max_iter)\n",
    "        \n",
    "        if val_Xs!=None:\n",
    "            print 'Validation accuracy:{:.4f}'.format(self.score(val_Xs, val_ys))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        if isinstance(X, scipy.sparse.csc.csc_matrix):\n",
    "            mul = np.dot(X, csc_matrix(self.weights)).toarray()\n",
    "        else:\n",
    "            mul = np.dot(X, self.weights)\n",
    "        probs = np.exp(mul + self.bias)\n",
    "        probs = np.concatenate((np.ones((probs.shape[0], 1)), probs), axis=1)\n",
    "        predicts = np.argmax(probs, axis=1)\n",
    "        return predicts\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        predicts = self.predict(X)\n",
    "        return np.sum(predicts==y,dtype=float)/X.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用20%的数据作为验证集(对比各种参数、特征选择的优劣) \n",
    "由于label分布不均匀，所以这里使用了Stratified的方式拆分数据集，保证train,val数据中各种label的比例是一致的。PS：这里没有再单独划分测试集是由于所有选择均未进行针对验证集的参数搜索(即不太可能出现对验证集overfitting)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_idx, val_idx = val_split(df_train.iloc[:, -2:], val_size=0.2)\n",
    "#val_idx, test_idx = val_split(df_train.iloc[val_idx, -2:], val_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 不同特征的影响\n",
    "以下四种特征  \n",
    "（1)1-gram, binary\n",
    "（2)1-gram, 计数，下同 \n",
    "（3)1-gram, 使用lemmatization  \n",
    "（4)1-gram, 使用lemmatization且删除仅出现一次的word和stop words   \n",
    "（5)2-gram  \n",
    "\n",
    "最终结果："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\" width=900>\n",
    "<tr>\n",
    "<th>Feature</th>\n",
    "<th>Train loss</th>\n",
    "<th>Val accuracy</th>\n",
    "<th>Time</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>1-gram, binary</td>\n",
    "<td>12.1930</td>\n",
    "<td>0.5652</td>\n",
    "<td>1min 51s</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>1-gram, count</td>\n",
    "<td>12.2055</td>\n",
    "<td>0.5639</td>\n",
    "<td>1min 53s</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>1-gram, count, lemmatization</td>\n",
    "<td>12.1434</td>\n",
    "<td>0.5652</td>\n",
    "<td>1min 55s</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>1-gram, count, lemmatization, trim words</td>\n",
    "<td>12.1707</td>\n",
    "<td>0.5655</td>\n",
    "<td>2min</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>2-gram, count</td>\n",
    "<td>12.7899</td>\n",
    "<td>0.5774</td>\n",
    "<td>4min 59s</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "其它训练参数，均保持一致。例如优化算法SGD，lr=0.1, C=0.001(l2正则比例)，200个iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果显示：效果最好的是2-gram，count。其次是1-gram+count+lemmatization+trim words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "lg = LogisticRegression(C=0.001, step=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. one-gram, binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train vocabulary size: 15181\n",
      "trainX shape:(124850, 15181)\n"
     ]
    }
   ],
   "source": [
    "wordDictionary = WordDictionary(n_grams=1, lemmatization=False)\n",
    "\n",
    "for data in df_train['Phrase']:\n",
    "    wordDictionary.addSentence(data)\n",
    "\n",
    "print \"Train vocabulary size: {}\".format(wordDictionary.n_words)\n",
    "\n",
    "#向量化\n",
    "train_Xs,train_ys = word2index(df_train.iloc[train_idx, -2:], wordDictionary, count=False)\n",
    "val_Xs, val_ys = word2index(df_train.iloc[val_idx, -2:], wordDictionary, count=False)\n",
    "print 'trainX shape:{}'.format(train_Xs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/200] loss:13.7027\n",
      "[20/200] loss:13.4544\n",
      "[30/200] loss:13.2877\n",
      "[40/200] loss:13.1539\n",
      "[50/200] loss:13.0414\n",
      "[60/200] loss:12.9441\n",
      "[70/200] loss:12.8583\n",
      "[80/200] loss:12.7813\n",
      "[90/200] loss:12.7114\n",
      "[100/200] loss:12.6473\n",
      "[110/200] loss:12.5880\n",
      "[120/200] loss:12.5328\n",
      "[130/200] loss:12.4812\n",
      "[140/200] loss:12.4326\n",
      "[150/200] loss:12.3867\n",
      "[160/200] loss:12.3432\n",
      "[170/200] loss:12.3018\n",
      "[180/200] loss:12.2624\n",
      "[190/200] loss:12.2248\n",
      "[200/200] loss:12.1889\n",
      "Validation accuracy:0.5677\n",
      "CPU times: user 1min 52s, sys: 4 ms, total: 1min 52s\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lg.fit(train_Xs, train_ys, val_Xs, val_ys, update=SGD, max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/200] loss:1.3405\n",
      "[20/200] loss:1.2912\n",
      "[30/200] loss:1.2559\n",
      "[40/200] loss:1.2275\n",
      "[50/200] loss:1.2035\n",
      "[60/200] loss:1.1825\n",
      "[70/200] loss:1.1639\n",
      "[80/200] loss:1.1472\n",
      "[90/200] loss:1.1319\n",
      "[100/200] loss:1.1179\n",
      "[110/200] loss:1.1049\n",
      "[120/200] loss:1.0929\n",
      "[130/200] loss:1.0817\n",
      "[140/200] loss:1.0712\n",
      "[150/200] loss:1.0613\n",
      "[160/200] loss:1.0519\n",
      "[170/200] loss:1.0431\n",
      "[180/200] loss:1.0347\n",
      "[190/200] loss:1.0268\n",
      "[200/200] loss:1.0192\n",
      "Validation accuracy:0.6148\n",
      "CPU times: user 1min 56s, sys: 16 ms, total: 1min 56s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lg = LogisticRegression(C=0.0, step=5.5)\n",
    "lg.fit(train_Xs, train_ys, val_Xs, val_ys, class_weights=None, update=SGD, max_iter=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. one-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train vocabulary size: 15181\n",
      "trainX shape:(124850, 15181)\n"
     ]
    }
   ],
   "source": [
    "wordDictionary = WordDictionary(n_grams=1, lemmatization=False)\n",
    "\n",
    "for data in df_train['Phrase']:\n",
    "    wordDictionary.addSentence(data)\n",
    "\n",
    "print \"Train vocabulary size: {}\".format(wordDictionary.n_words)\n",
    "\n",
    "#向量化\n",
    "train_Xs,train_ys = word2index(df_train.iloc[train_idx, -2:], wordDictionary)\n",
    "val_Xs, val_ys = word2index(df_train.iloc[val_idx, -2:], wordDictionary)\n",
    "print 'trainX shape:{}'.format(train_Xs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/200] loss:13.7135\n",
      "[20/200] loss:13.4521\n",
      "[30/200] loss:13.2838\n",
      "[40/200] loss:13.1537\n",
      "[50/200] loss:13.0454\n",
      "[60/200] loss:12.9517\n",
      "[70/200] loss:12.8687\n",
      "[80/200] loss:12.7938\n",
      "[90/200] loss:12.7254\n",
      "[100/200] loss:12.6624\n",
      "[110/200] loss:12.6038\n",
      "[120/200] loss:12.5491\n",
      "[130/200] loss:12.4977\n",
      "[140/200] loss:12.4493\n",
      "[150/200] loss:12.4035\n",
      "[160/200] loss:12.3600\n",
      "[170/200] loss:12.3186\n",
      "[180/200] loss:12.2792\n",
      "[190/200] loss:12.2416\n",
      "[200/200] loss:12.2055\n",
      "Validation accuracy:0.5639\n",
      "CPU times: user 1min 53s, sys: 0 ns, total: 1min 53s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lg.fit(train_Xs, train_ys, val_Xs, val_ys, update=SGD, max_iter=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. 1-gram, 使用lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train vocabulary size: 15759\n",
      "trainX shape:(124850, 15759)\n"
     ]
    }
   ],
   "source": [
    "wordDictionary = WordDictionary(n_grams=1, lemmatization=True)\n",
    "\n",
    "for data in df_train['Phrase']:\n",
    "    wordDictionary.addSentence(data)\n",
    "\n",
    "print \"Train vocabulary size: {}\".format(wordDictionary.n_words)\n",
    "\n",
    "#向量化\n",
    "train_Xs,train_ys = word2index(df_train.iloc[train_idx, -2:], wordDictionary)\n",
    "val_Xs, val_ys = word2index(df_train.iloc[val_idx, -2:], wordDictionary)\n",
    "print 'trainX shape:{}'.format(train_Xs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/200] loss:13.6924\n",
      "[20/200] loss:13.4152\n",
      "[30/200] loss:13.2374\n",
      "[40/200] loss:13.1016\n",
      "[50/200] loss:12.9898\n",
      "[60/200] loss:12.8940\n",
      "[70/200] loss:12.8095\n",
      "[80/200] loss:12.7337\n",
      "[90/200] loss:12.6647\n",
      "[100/200] loss:12.6012\n",
      "[110/200] loss:12.5424\n",
      "[120/200] loss:12.4875\n",
      "[130/200] loss:12.4360\n",
      "[140/200] loss:12.3875\n",
      "[150/200] loss:12.3416\n",
      "[160/200] loss:12.2981\n",
      "[170/200] loss:12.2567\n",
      "[180/200] loss:12.2172\n",
      "[190/200] loss:12.1795\n",
      "[200/200] loss:12.1434\n",
      "Validation accuracy:0.5652\n",
      "CPU times: user 1min 55s, sys: 4 ms, total: 1min 55s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lg.fit(train_Xs, train_ys, val_Xs, val_ys, update=SGD, max_iter=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.4. 1-gram, 使用lemmatization且删除仅出现一次的word和stop words   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train vocabulary size: 15759\n",
      "[('y', 1), ('tu', 1), ('prechewed', 1), ('aggrieved', 1), (u'casing', 1), ('recovers', 1), ('roland', 1), ('lifted', 1), ('credulity', 1), ('omitted', 1), ('petter', 1), ('harmlessly', 1), ('retrospective', 1), ('foreshadowing', 1), ('marinated', 1), ('casings', 1), ('piles', 1), ('implied', 1), ('underventilated', 1), ('unsaid', 1), ('joshua', 1), ('upends', 1), ('anciently', 1), ('overstylized', 1), ('luis', 1)]\n",
      "Finish reindex\n",
      "trainX shape:(124850, 15729)\n"
     ]
    }
   ],
   "source": [
    "wordDictionary = WordDictionary(n_grams=1, lemmatization=True)\n",
    "\n",
    "for data in df_train['Phrase']:\n",
    "    wordDictionary.addSentence(data)\n",
    "\n",
    "print \"Train vocabulary size: {}\".format(wordDictionary.n_words)\n",
    "\n",
    "#删除词语\n",
    "onetime_words = wordDictionary.filterWords(min_val=1)\n",
    "stop_words = ['a','an','the','at', 'on', 'in']\n",
    "drop_words = onetime_words + stop_words\n",
    "\n",
    "wordDictionary.dropAndReindex(drop_words)\n",
    "\n",
    "#向量化\n",
    "train_Xs,train_ys = word2index(df_train.iloc[train_idx, -2:], wordDictionary)\n",
    "val_Xs, val_ys = word2index(df_train.iloc[val_idx, -2:], wordDictionary)\n",
    "print 'trainX shape:{}'.format(train_Xs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/200] loss:13.7368\n",
      "[20/200] loss:13.4548\n",
      "[30/200] loss:13.2756\n",
      "[40/200] loss:13.1393\n",
      "[50/200] loss:13.0271\n",
      "[60/200] loss:12.9306\n",
      "[70/200] loss:12.8455\n",
      "[80/200] loss:12.7688\n",
      "[90/200] loss:12.6990\n",
      "[100/200] loss:12.6347\n",
      "[110/200] loss:12.5751\n",
      "[120/200] loss:12.5194\n",
      "[130/200] loss:12.4672\n",
      "[140/200] loss:12.4180\n",
      "[150/200] loss:12.3715\n",
      "[160/200] loss:12.3274\n",
      "[170/200] loss:12.2855\n",
      "[180/200] loss:12.2455\n",
      "[190/200] loss:12.2073\n",
      "[200/200] loss:12.1707\n",
      "Validation accuracy:0.5655\n",
      "CPU times: user 2min, sys: 12 ms, total: 2min\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lg.fit(train_Xs, train_ys, val_Xs, val_ys, update=SGD, max_iter=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. two-gram  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train vocabulary size: 98401\n",
      "trainX shape:(124850, 98401)\n"
     ]
    }
   ],
   "source": [
    "wordDictionary = WordDictionary(n_grams=2, lemmatization=False)\n",
    "\n",
    "for data in df_train['Phrase']:\n",
    "    wordDictionary.addSentence(data)\n",
    "\n",
    "print \"Train vocabulary size: {}\".format(wordDictionary.n_words)\n",
    "\n",
    "#向量化\n",
    "train_Xs,train_ys = word2index(df_train.iloc[train_idx, -2:], wordDictionary)\n",
    "val_Xs, val_ys = word2index(df_train.iloc[val_idx, -2:], wordDictionary)\n",
    "print 'trainX shape:{}'.format(train_Xs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/200] loss:17.9426\n",
      "[20/200] loss:13.1355\n",
      "[30/200] loss:14.3905\n",
      "[40/200] loss:14.0615\n",
      "[50/200] loss:13.8706\n",
      "[60/200] loss:14.5525\n",
      "[70/200] loss:14.1135\n",
      "[80/200] loss:13.6519\n",
      "[90/200] loss:13.8325\n",
      "[100/200] loss:13.9594\n",
      "[110/200] loss:13.5596\n",
      "[120/200] loss:13.3854\n",
      "[130/200] loss:13.2536\n",
      "[140/200] loss:13.3453\n",
      "[150/200] loss:13.1500\n",
      "[160/200] loss:13.1256\n",
      "[170/200] loss:12.9953\n",
      "[180/200] loss:12.9514\n",
      "[190/200] loss:12.8524\n",
      "[200/200] loss:12.7899\n",
      "Validation accuracy:0.5774\n",
      "CPU times: user 4min 59s, sys: 0 ns, total: 4min 59s\n",
      "Wall time: 4min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lg.fit(train_Xs, train_ys, val_Xs, val_ys, update=SGD, max_iter=200, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. GD与SGD对比\n",
    "特征: 1-gram, binary.  \n",
    "learning rate: 0.1, C:0.001, iterations: 200.  \n",
    "PS: SGD在上节中已测试，这里只使用GD再跑一次"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\" width=900>\n",
    "<tr>\n",
    "<th>Algorithm</th>\n",
    "<th>Train loss</th>\n",
    "<th>Val accuracy</th>\n",
    "<th>Time</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>SGD</td>\n",
    "<td>12.1930</td>\n",
    "<td>0.5652</td>\n",
    "<td>1min 51s</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>GD</td>\n",
    "<td>13.2431</td>\n",
    "<td>0.5388</td>\n",
    "<td>1min 53s</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里显示相同参数下，SGD能得到更高的validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train vocabulary size: 15181\n",
      "trainX shape:(124850, 15181)\n"
     ]
    }
   ],
   "source": [
    "wordDictionary = WordDictionary(n_grams=1, lemmatization=False)\n",
    "\n",
    "for data in df_train['Phrase']:\n",
    "    wordDictionary.addSentence(data)\n",
    "\n",
    "print \"Train vocabulary size: {}\".format(wordDictionary.n_words)\n",
    "\n",
    "#向量化\n",
    "train_Xs,train_ys = word2index(df_train.iloc[train_idx, -2:], wordDictionary, count=False)\n",
    "val_Xs, val_ys = word2index(df_train.iloc[val_idx, -2:], wordDictionary, count=False)\n",
    "print 'trainX shape:{}'.format(train_Xs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/200] loss:14.6441\n",
      "[20/200] loss:14.1728\n",
      "[30/200] loss:13.9739\n",
      "[40/200] loss:13.8538\n",
      "[50/200] loss:13.7691\n",
      "[60/200] loss:13.7035\n",
      "[70/200] loss:13.6495\n",
      "[80/200] loss:13.6029\n",
      "[90/200] loss:13.5616\n",
      "[100/200] loss:13.5239\n",
      "[110/200] loss:13.4890\n",
      "[120/200] loss:13.4563\n",
      "[130/200] loss:13.4254\n",
      "[140/200] loss:13.3961\n",
      "[150/200] loss:13.3680\n",
      "[160/200] loss:13.3411\n",
      "[170/200] loss:13.3153\n",
      "[180/200] loss:13.2903\n",
      "[190/200] loss:13.2663\n",
      "[200/200] loss:13.2431\n",
      "Validation accuracy:0.5388\n",
      "CPU times: user 1min 53s, sys: 8 ms, total: 1min 53s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lg.fit(train_Xs, train_ys, val_Xs, val_ys, update=GradientDescent, max_iter=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Learning rate的选择。\n",
    "特征: 1-gram, binary.  \n",
    "C:0.001, iterations: 200.  \n",
    "PS: lr=0.1已经跑过了，这里只跑0.05, 0.5, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\" width=900>\n",
    "<tr>\n",
    "<th>Learning rate</th>\n",
    "<th>Train loss</th>\n",
    "<th>Val accuracy</th>\n",
    "<th>Time</th>\n",
    "</tr>\n",
    "<td>0.05</td>\n",
    "<td>12.6509</td>\n",
    "<td>0.5536</td>\n",
    "<td>1min 51s</td>\n",
    "<tr>\n",
    "<td>0.1</td>\n",
    "<td>12.1930</td>\n",
    "<td>0.5652</td>\n",
    "<td>1min 51s</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>0.5</td>\n",
    "<td>12.3858</td>\n",
    "<td><font color='red'>0.5883</font></td>\n",
    "<td>1min 47s</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>29.9642</td>\n",
    "<td>0.3516</td>\n",
    "<td>1min 47s</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lg = LogisticRegression(C=0.001, step=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/200] loss:13.9693\n",
      "[20/200] loss:13.7015\n",
      "[30/200] loss:13.5601\n",
      "[40/200] loss:13.4550\n",
      "[50/200] loss:13.3669\n",
      "[60/200] loss:13.2894\n",
      "[70/200] loss:13.2197\n",
      "[80/200] loss:13.1563\n",
      "[90/200] loss:13.0980\n",
      "[100/200] loss:13.0442\n",
      "[110/200] loss:12.9941\n",
      "[120/200] loss:12.9472\n",
      "[130/200] loss:12.9031\n",
      "[140/200] loss:12.8616\n",
      "[150/200] loss:12.8222\n",
      "[160/200] loss:12.7847\n",
      "[170/200] loss:12.7491\n",
      "[180/200] loss:12.7150\n",
      "[190/200] loss:12.6823\n",
      "[200/200] loss:12.6509\n",
      "Validation accuracy:0.5536\n",
      "CPU times: user 1min 51s, sys: 0 ns, total: 1min 51s\n",
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lg.fit(train_Xs, train_ys, val_Xs, val_ys, update=SGD, max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lg = LogisticRegression(C=0.001, step=6.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/200] loss:1.4949\n",
      "[20/200] loss:1.4652\n",
      "[30/200] loss:1.4508\n",
      "[40/200] loss:1.4428\n",
      "[50/200] loss:1.4381\n",
      "[60/200] loss:1.4352\n",
      "[70/200] loss:1.4335\n",
      "[80/200] loss:1.4324\n",
      "[90/200] loss:1.4317\n",
      "[100/200] loss:1.4313\n",
      "[110/200] loss:1.4310\n",
      "[120/200] loss:1.4309\n",
      "[130/200] loss:1.4308\n",
      "[140/200] loss:1.4307\n",
      "[150/200] loss:1.4306\n",
      "[160/200] loss:1.4306\n",
      "[170/200] loss:1.4306\n",
      "[180/200] loss:1.4306\n",
      "[190/200] loss:1.4306\n",
      "[200/200] loss:1.4306\n",
      "Validation accuracy:0.4463\n",
      "CPU times: user 1min 52s, sys: 8 ms, total: 1min 52s\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lg.fit(train_Xs, train_ys, val_Xs, val_ys, class_weights=None, update=SGD, max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lg = LogisticRegression(C=0.001, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/200] loss:39.8443\n",
      "[20/200] loss:37.7512\n",
      "[30/200] loss:36.2919\n",
      "[40/200] loss:35.1643\n",
      "[50/200] loss:34.2796\n",
      "[60/200] loss:33.5689\n",
      "[70/200] loss:32.9854\n",
      "[80/200] loss:32.4984\n",
      "[90/200] loss:32.0869\n",
      "[100/200] loss:31.7358\n",
      "[110/200] loss:31.4340\n",
      "[120/200] loss:31.1729\n",
      "[130/200] loss:30.9459\n",
      "[140/200] loss:30.7475\n",
      "[150/200] loss:30.5735\n",
      "[160/200] loss:30.4203\n",
      "[170/200] loss:30.2850\n",
      "[180/200] loss:30.1653\n",
      "[190/200] loss:30.0589\n",
      "[200/200] loss:29.9642\n",
      "Validation accuracy:0.3516\n",
      "CPU times: user 1min 47s, sys: 0 ns, total: 1min 47s\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lg.fit(train_Xs, train_ys, val_Xs, val_ys, update=SGD, max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
